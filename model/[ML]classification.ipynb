{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, RobustScaler\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import classification_report, accuracy_score\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "import seaborn as sns\r\n",
    "import lightgbm as lgb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "data= pd.read_csv('./data/final_data_v2.csv')\r\n",
    "print(data.columns)\r\n",
    "print(data.isnull().sum())\r\n",
    "print(data.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['paragraph_txt', 'essay_level', 'student_grade_group', 'org_paragraph',\n",
      "       'org', 'org_essay', 'org_coherence', 'org_quantity', 'con_novelty',\n",
      "       'con_clearance', 'con', 'con_prompt', 'con_description', 'exp_style',\n",
      "       'exp_grammar', 'exp', 'exp_vocab', 'essay_grade', 'essay_main_subject',\n",
      "       'punctuation_marks', 'ending_of_a_word', 'word_order', 'diff',\n",
      "       'Rouge_l_f1', 'paragraph_scoreT_avg'],\n",
      "      dtype='object')\n",
      "paragraph_txt           0\n",
      "essay_level             0\n",
      "student_grade_group     0\n",
      "org_paragraph           0\n",
      "org                     0\n",
      "org_essay               0\n",
      "org_coherence           0\n",
      "org_quantity            0\n",
      "con_novelty             0\n",
      "con_clearance           0\n",
      "con                     0\n",
      "con_prompt              0\n",
      "con_description         0\n",
      "exp_style               0\n",
      "exp_grammar             0\n",
      "exp                     0\n",
      "exp_vocab               0\n",
      "essay_grade             0\n",
      "essay_main_subject      0\n",
      "punctuation_marks       0\n",
      "ending_of_a_word        0\n",
      "word_order              0\n",
      "diff                    0\n",
      "Rouge_l_f1              0\n",
      "paragraph_scoreT_avg    0\n",
      "dtype: int64\n",
      "                                       paragraph_txt  essay_level  \\\n",
      "0  내가 5~7살쯤에 있던 일이었다. #@문장구분# 저는 엄마, 누나와 함께 버스를 타...            3   \n",
      "1  나는 생물학자가 되고 싶다. #@문장구분# 어릴적부터 생물관련책을 읽으며 생물학을 ...            2   \n",
      "2  나는 최근에 ‘스파이더맨:파 프롬 홈’ 이라는 영화를 보았다. #@문장구분# 먼저 ...            3   \n",
      "3  내가 생각하는 참된스승이란 자신의 제자의 잘못된점을 바로 잡아주고 올바른 길로 인도...            2   \n",
      "4  내가 최근에 본 영화 스파이더맨 파 프롬 홈은 주인공인 스파이더맨이 학교에서 수학여...            3   \n",
      "\n",
      "  student_grade_group  org_paragraph  org  org_essay  org_coherence  \\\n",
      "0                  초등              5    2          0              0   \n",
      "1                  고등              3    2          3              2   \n",
      "2                  고등              4    2          2              2   \n",
      "3                  중등              5    2          1              1   \n",
      "4                  고등              4    2          2              2   \n",
      "\n",
      "   org_quantity  con_novelty  con_clearance  ...  exp  exp_vocab  essay_grade  \\\n",
      "0             1            2              4  ...    4          3       초등_4학년   \n",
      "1             1            1              4  ...    4          3       고등_3학년   \n",
      "2             1            1              4  ...    4          3       고등_1학년   \n",
      "3             1            2              4  ...    4          3       중등_1학년   \n",
      "4             1            1              4  ...    4          3       고등_1학년   \n",
      "\n",
      "   essay_main_subject  punctuation_marks  ending_of_a_word  word_order diff  \\\n",
      "0               나의 선행                  0                 0           0   14   \n",
      "1        나의 진로를 위한 노력                  0                 0           1   30   \n",
      "2            영화/독서감상문                  1                 0           3   16   \n",
      "3               참된 스승                  0                 0           0   17   \n",
      "4            영화/독서감상문                  0                 0           0   12   \n",
      "\n",
      "  Rouge_l_f1  paragraph_scoreT_avg  \n",
      "0   0.994793              2.000000  \n",
      "1   0.994596              3.000000  \n",
      "2   0.979464              2.944444  \n",
      "3   0.980118              1.833333  \n",
      "4   0.985934              3.000000  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# delete_columns= ['student_grade_group', 'essay_main_subject', 'essay_grade']\r\n",
    "\r\n",
    "# data= data.drop(delete_columns, axis= 1)\r\n",
    "# data.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# seed= 42\r\n",
    "# train, test= train_test_split(data, test_size= 0.2, random_state= seed)\r\n",
    "# train, val= train_test_split(train,test_size= 0.2, random_state= seed)\r\n",
    "\r\n",
    "# train.to_csv('./data/train_with_para.csv', index= False)\r\n",
    "# test.to_csv('./data/test_with_para.csv', index= False)\r\n",
    "# val.to_csv('./data/validation_with_para.csv', index= False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "train= pd.read_csv('./data/train.csv')\r\n",
    "test= pd.read_csv('./data/test.csv')\r\n",
    "valid= pd.read_csv('./data/validation.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "def get_params():\r\n",
    "    params = {'learning_rate': 0.01, \r\n",
    "          'max_depth': 64, \r\n",
    "          'boosting': 'gbdt', \r\n",
    "          'objective': 'multiclass', \r\n",
    "          'metric': 'multi_logloss', \r\n",
    "          'num_leaves': 8, \r\n",
    "          'min_data': 30, \r\n",
    "          'num_classes': 4, \r\n",
    "          'seed':42}\r\n",
    "\r\n",
    "    return params"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "def get_label(pred_df):\r\n",
    "    # pred_df= pred_df.sort_values(by=['paragraph_scoreT_avg'], ascending= False)\r\n",
    "    # length= len(pred_df)\r\n",
    "    \r\n",
    "    # label= [3]* int(0.25*length) + [2]* int(0.25* length) + [1] * int(0.25* length) + [0]* (length- int(0.25*length) - int(0.25* length)- int(0.25* length))\r\n",
    "    label= []\r\n",
    "    for i in range(len(pred_df)):\r\n",
    "        # print(pred_df.iloc[i]['paragraph_scoreT_avg'])\r\n",
    "        if pred_df.iloc[i]['paragraph_scoreT_avg'] == 3.0:\r\n",
    "            label.append(3)\r\n",
    "        elif pred_df.iloc[i]['paragraph_scoreT_avg'] >= 2.75:\r\n",
    "            label.append(2)\r\n",
    "        elif pred_df.iloc[i]['paragraph_scoreT_avg'] >= 2.333335:\r\n",
    "            label.append(1)\r\n",
    "        else:\r\n",
    "            label.append(0)\r\n",
    "    pred_df['label']= label\r\n",
    "    return pred_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "train= get_label(train)\n",
    "train_x= train.drop(['paragraph_scoreT_avg', 'label'], axis= 1)\n",
    "train_y= train['label']\n",
    "\n",
    "valid= get_label(valid)\n",
    "val_x= valid.drop(['paragraph_scoreT_avg', 'label'], axis= 1)\n",
    "val_y= valid['label']\n",
    "\n",
    "test= get_label(test)\n",
    "test_x= test.drop(['paragraph_scoreT_avg', 'label'], axis= 1)\n",
    "test_y= test['label']\n",
    "pd.DataFrame(test_y).to_csv('./final_test_y.csv', index= False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# scaler= RobustScaler()\n",
    "# train_x= scaler.fit_transform(train_x)\n",
    "# val_x= scaler.transform(val_x)\n",
    "# test_x= scaler.transform(test_x)\n",
    "\n",
    "trainset= lgb.Dataset(train_x, label= train_y)\n",
    "valset= lgb.Dataset(val_x, label= val_y)\n",
    "testset= lgb.Dataset(test_x, label= test_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "params= get_params()\n",
    "model= lgb.train(params, trainset, 1000, testset, verbose_eval=100, early_stopping_rounds= 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 414\n",
      "[LightGBM] [Info] Number of data points in the train set: 3840, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score -1.298589\n",
      "[LightGBM] [Info] Start training from score -1.376963\n",
      "[LightGBM] [Info] Start training from score -1.416968\n",
      "[LightGBM] [Info] Start training from score -1.459762\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's multi_logloss: 1.29821\n",
      "[200]\tvalid_0's multi_logloss: 1.28178\n",
      "[300]\tvalid_0's multi_logloss: 1.28003\n",
      "Early stopping, best iteration is:\n",
      "[277]\tvalid_0's multi_logloss: 1.27946\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "pred_train = model.predict(train_x)\n",
    "pred_val= model.predict(test_x)\n",
    "print(pred_val)\n",
    "tmp_df= pd.DataFrame(pred_val)\n",
    "tmp_df.columns= [0, 1, 2, 3]\n",
    "tmp_df.to_csv('./lightgbm_logits.csv', index= False)\n",
    "\n",
    "pred_val= np.argmax(pred_val, axis= 1)\n",
    "\n",
    "print(classification_report(pred_val, test_y))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.15828239 0.20975432 0.31336402 0.31859927]\n",
      " [0.52388047 0.16009029 0.14985894 0.16617031]\n",
      " [0.49183613 0.20228367 0.17592399 0.12995621]\n",
      " ...\n",
      " [0.09108296 0.30173522 0.18921106 0.41797077]\n",
      " [0.08330528 0.36385926 0.35786966 0.19496581]\n",
      " [0.50848987 0.16350644 0.13330422 0.19469947]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.44      0.56       544\n",
      "           1       0.26      0.31      0.28       241\n",
      "           2       0.27      0.33      0.30       230\n",
      "           3       0.22      0.36      0.27       185\n",
      "\n",
      "    accuracy                           0.38      1200\n",
      "   macro avg       0.37      0.36      0.35      1200\n",
      "weighted avg       0.48      0.38      0.41      1200\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}